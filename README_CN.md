<p align="left">
    ä¸­æ–‡ ï½œ &nbsp <a href="./README.md">English</a></a>&nbsp
</p>
<br>

<div align="center">
<h1>
  360æ™ºè„‘
</h1>
</div>
<div align="center">
    ğŸ¤— <a href="https://huggingface.co/qihoo360">Hugging Face</a>&nbsp&nbsp | &nbsp&nbsp
    ğŸ¤– <a href="https://modelscope.cn/organization/360zhinao">ModelScope</a>&nbsp&nbsp ï½œ &nbsp&nbsp
    ğŸ’¬ <a href="./assets/WeChat.png">WeChat (å¾®ä¿¡)</a>&nbsp&nbsp
</div>
<br>
<p align="center">
 æ¬¢è¿è®¿é—®360æ™ºè„‘å®˜ç½‘<a href="https://ai.360.com"> https://ai.360.com </a>ä½“éªŒæ›´å¤šæ›´å¼ºå¤§çš„åŠŸèƒ½ã€‚
</p>

<br>

# æ¨¡å‹ä»‹ç»
 ğŸ‰ğŸ‰ğŸ‰æˆ‘ä»¬å¼€æºäº†360æ™ºè„‘å¤§æ¨¡å‹çš„ç³»åˆ—å·¥ä½œï¼Œæœ¬æ¬¡å¼€æºäº†ä»¥ä¸‹æ¨¡å‹ï¼š
 - **360Zhinao2-7B-Base**
 - **360Zhinao2-7B-Chat-4K**
 - **360Zhinao2-7B-Chat-32K**
 - **360Zhinao2-7B-Chat-360K**

360æ™ºè„‘å¤§æ¨¡å‹ç‰¹ç‚¹å¦‚ä¸‹ï¼š
- **åŸºç¡€æ¨¡å‹**ï¼šé‡‡â½¤å½“å‰ä¸»æµçš„ä¸¤é˜¶æ®µè®­ç»ƒâ½…æ³•ï¼Œç¬¬â¼€é˜¶æ®µé‡‡ç”¨cosineå­¦ä¹ ç‡æ€»å…±è®­ç»ƒ10T
tokenï¼Œç¬¬äºŒé˜¶æ®µæˆ‘ä»¬åŠ â¼¤äº†â¾¼è´¨é‡æ•°æ®çš„å â½ï¼Œè®­ç»ƒäº†100Bâ¾¼è´¨é‡tokenï¼Œå­¦ä¹ ç‡LRç›´æ¥decayåˆ°0ã€‚**360Zhinao2-7Bæ€»å…±è®­ç»ƒæ•°æ®é‡è¾¾10.1T token**ã€‚
- **å¯¹è¯æ¨¡å‹**ï¼šå…·æœ‰å¼ºå¤§çš„å¯¹è¯èƒ½åŠ›ï¼Œå¼€æ”¾4Kã€32Kã€360Kä¸‰ç§ä¸åŒæ–‡æœ¬é•¿åº¦ã€‚

<br>

# æ›´æ–°ä¿¡æ¯
- [2024.11.18] ğŸ”¥ğŸ”¥ğŸ”¥æˆ‘ä»¬å‘å¸ƒäº†360Zhinao2-7Bï¼ŒåŒæ—¶å¼€æ”¾Baseæ¨¡å‹å’Œ4Kã€32Kã€360Kä¸‰ç§æ–‡æœ¬é•¿åº¦çš„Chatæ¨¡å‹ã€‚
- [2024.05.23] æˆ‘ä»¬å‘å¸ƒäº†360Zhinao-searchä»¥åŠ360Zhinao-1.8B-Rerankingä¸¤ä¸ªæ¨¡å‹ï¼Œåˆ†åˆ«åœ¨[C-MTEB æ¦œå•](https://huggingface.co/spaces/mteb/leaderboard)çš„Retrievalå’ŒRerankingä»»åŠ¡ä¸Šæ’åç¬¬ä¸€ã€‚
- [2024.05.20] æˆ‘ä»¬å°†llama3çš„çª—å£é•¿åº¦æ‰©å±•åˆ°360kå¹¶å‘å¸ƒäº†**llama3-8B-360Zhinao-360k-Instruct**<a href="https://huggingface.co/qihoo360/llama3-8B-360Zhinao-360k-Instruct">ğŸ¤—</a>
- [2024.04.12] æˆ‘ä»¬å‘å¸ƒäº†360Zhinao-7B 1.0ç‰ˆæœ¬ï¼ŒåŒæ—¶å¼€æ”¾Baseæ¨¡å‹å’Œ4Kã€32Kã€360Kä¸‰ç§æ–‡æœ¬é•¿åº¦çš„Chatæ¨¡å‹ã€‚
æŠ€æœ¯æŠ¥å‘Šè¯¦è§[arXiv](https://arxiv.org/abs/2405.13386)ã€‚

<br>

# ç›®å½•
- [ä¸‹è½½åœ°å€](#ä¸‹è½½åœ°å€)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ¨¡å‹æ¨ç†](#æ¨¡å‹æ¨ç†)
- [æ¨¡å‹å¾®è°ƒ](#æ¨¡å‹å¾®è°ƒ)
- [è®¸å¯è¯](#è®¸å¯è¯)

<br>

# ä¸‹è½½åœ°å€
æœ¬æ¬¡å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½é“¾æ¥è§ä¸‹è¡¨ï¼š
| Size | Model | BF16 | Int4|
|:-:|-|:-:|:-:|
| 7B | 360Zhinao2-7B-Base | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Base/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Base">ğŸ¤—</a> |  |
| 7B | 360Zhinao2-7B-Chat-4K | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Chat-4K/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Chat-4K">ğŸ¤—</a> | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Chat-4K-Int4/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Chat-4K-Int4">ğŸ¤—</a> |
| 7B | 360Zhinao2-7B-Chat-32K | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Chat-32K/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Chat-32K">ğŸ¤—</a> | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Chat-32K-Int4/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Chat-32K-Int4">ğŸ¤—</a> |
| 7B | 360Zhinao2-7B-Chat-360K | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Chat-360K/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Chat-360K">ğŸ¤—</a> | <a href="https://modelscope.cn/models/360zhinao/360Zhinao2-7B-Chat-360K-Int4/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao2-7B-Chat-360K-Int4">ğŸ¤—</a> |

<br>

# æ¨¡å‹è¯„ä¼°

## åŸºç¡€æ¨¡å‹

æˆ‘ä»¬ä½¿â½¤äº†å¼€æºâ¼¯å…·opencompasså¯¹æ¨¡å‹è¿›â¾è¯„ä¼°ï¼Œå¯¹â½äº†è¿‘åŠå¹´å›½å†…å¤–å¼€æºçš„10Bä»¥ä¸‹æ¨¡å‹ï¼Œ
360Zhinao2-7Bå…·å¤‡è¾ƒå¼ºçš„ç«äº‰â¼’ã€‚360Zhinao2-7Båœ¨CEvalï¼ˆä¸­â½‚
è€ƒè¯•ï¼‰ã€C3ï¼ˆä¸­â½‚é˜…è¯»ç†è§£ï¼‰ã€lcstsï¼ˆä¸­â½‚çŸ­â½‚æœ¬æ‘˜è¦ï¼‰ç­‰ä¸­â½‚benchmarkä¸Šè¡¨ç°ä¸ä¿—ï¼Œä¸­â½‚
benchmarkå‡åˆ†æ’åç¬¬â¼€ã€‚åœ¨æŒ‘æˆ˜æ€§çš„ç«èµ›æ•°å­¦æ•°æ®é›†mathä¸Šï¼ŒåŒæ ·æ’åç¬¬â¼€ã€‚**360Zhinao2-7Bæ¨¡
å‹åœ¨ä¸­â½‚å¤„ç†èƒ½â¼’ã€å¤æ‚æ•°å­¦æ¨ç†èƒ½â¼’ä¸¤ä¸ªâ½…â¾¯ï¼Œå…·å¤‡ä¼˜åŠ¿ã€‚**

<table>
	<tr>
	    <td>Type</td><td>Datasets</td><td>language</td><td>glm4-9b</td><td>Qwen2.5-7B</td><td>internlm2.5-7b</td><td>Yi1.5-9B</td><td>gemma2-9b</td><td>Llama3.1-8B</td><td>360Zhinao2-7B</td>
	</tr>
	<tr>
	    <td rowspan="5">Exam</td><td>ceval</td><td>zh</td><td>75.83</td><td>81.41</td><td>77.71</td><td>73.51</td><td>56.36</td><td>51.67</td><td><strong>83.04</strong></td>
	</tr>
    <tr>
        <td>mmlu</td><td>en</td><td>75.5</td><td>75.5</td><td>71.55</td><td>71.43</td><td>72.22</td><td>66.75</td><td>67.84</td>
    </tr>
    <tr>
        <td>cmmlu</td><td>zh</td><td>74.24</td><td>81.79</td><td>78.77</td><td>74.2</td><td>58.89</td><td>52.49</td><td>73.8</td>
    </tr>
    <tr>
        <td>ARC-c</td><td>en</td><td>94.92</td><td>80</td><td>85.08</td><td>87.46</td><td>77.63</td><td>80.68</td><td>87.12</td>
    </tr>
    <tr>
        <td>ARC-e</td><td>en</td><td>98.41</td><td>84.83</td><td>95.24</td><td>94.53</td><td>78.84</td><td>89.77</td><td>92.77</td>
    </tr>
    <tr>
        <td rowspan="2">Language</td><td>WiC</td><td>en</td><td>51.57</td><td>52.82</td><td>50.78</td><td>50.63</td><td>50.47</td><td>50</td><td>49.84</td>
    </tr>
    <tr>
        <td>WSC</td><td>en</td><td>68.27</td><td>68.27</td><td>69.23</td><td>66.35</td><td>68.27</td><td>67.31</td><td>65.38</td>
    </tr>
    <tr>
        <td rowspan="2">Knowledge</td>
        <td>BoolQ</td><td>en</td><td>81.8</td><td>83.88</td><td>89.51</td><td>84.46</td><td>85.6</td><td>82.2</td><td>88.29</td>
    </tr>
    <tr>
        <td>commonsense_qa</td><td>en</td><td>71.17</td><td>73.22</td><td>68.55</td><td>71.58</td><td>68.47</td><td>71.25</td><td>69.78</td>
    </tr>
    <tr>
        <td rowspan="6">Understanding</td>
        <td>C3</td><td>zh</td><td>91.51</td><td>92</td><td>93.04</td><td>85.86</td><td>81.64</td><td>83.51</td><td><strong>93.26</strong></td>
    </tr>
    <tr>
        <td>race-middle</td><td>en</td><td>91.99</td><td>91.02</td><td>92.06</td><td>91.16</td><td>88.09</td><td>81.69</td><td>90.46</td>
    </tr>
    <tr>
        <td>race-high</td><td>en</td><td>90.71</td><td>87.91</td><td>90.08</td><td>88.34</td><td>82.08</td><td>78.73</td><td>86.74</td>
    </tr>
    <tr>
        <td>lcsts</td><td>zh</td><td>18.29</td><td>15.82</td><td>15.96</td><td>16.49</td><td>10.62</td><td>17.29</td><td><strong>18.61</strong></td>
    </tr>
    <tr>
        <td>eprstmt-dev</td><td>zh</td><td>91.88</td><td>86.88</td><td>91.25</td><td>91.88</td><td>48.12</td><td>83.12</td><td>90</td>
    </tr>
    <tr>
        <td>lambada</td><td>en</td><td>71.67</td><td>71.14</td><td>69.98</td><td>70.64</td><td>75.43</td><td>74.23</td><td>72.56</td>
    </tr>
    <tr>
        <td rowspan="3">Reasoning</td>
        <td>hellaswag</td><td>en</td><td>70.25</td><td>72.76</td><td>70.38</td><td>71.55</td><td>66.83</td><td>74.65</td><td>71.49</td>
    </tr>
    <tr>
        <td>siqa</td><td>en</td><td>81.73</td><td>72.52</td><td>78.97</td><td>76.2</td><td>58.96</td><td>64.18</td><td>77.12</td>
    </tr>
    <tr>
        <td>bbh</td><td>en</td><td>73.68</td><td>54.63</td><td>59.43</td><td>67.86</td><td>68.45</td><td>59.9</td><td>46.54</td>
    </tr>
    <tr>
        <td rowspan="2">Code</td>
        <td>humaneval</td><td>en</td><td>69.51</td><td>75</td><td>60.37</td><td>26.22</td><td>5.49</td><td>27.44</td><td>60.98</td>
    </tr>
    <tr>
        <td>mbpp</td><td>en</td><td>60</td><td>60</td><td>43.6</td><td>56.8</td><td>51.2</td><td>42.6</td><td>54</td>
    </tr>
    <tr>
        <td rowspan="2">Math</td>
        <td>math</td><td>en</td><td>26.86</td><td>38</td><td>27.14</td><td>27.06</td><td>28.52</td><td>15.32</td><td><strong>38.34</strong></td>
    </tr>
    <tr>
        <td>gsm8k</td><td>en</td><td>78.54</td><td>79.76</td><td>52.54</td><td>71.11</td><td>73.09</td><td>56.25</td><td>75.51</td>
    </tr>
    <tr>
        <td rowspan="2">Overall</td>
        <td>avg_zh</td><td></td><td>70.35</td><td>71.58</td><td>71.35</td><td>68.39</td><td>51.13</td><td>57.62</td><td><strong>71.74</strong></td>
    </tr>
    <tr>
        <td>avg_all</td><td></td><td>73.11</td><td>71.78</td><td>69.60</td><td>68.88</td><td>61.60</td><td>62.32</td><td>70.61</td>
    </tr>
</table>


## Chatæ¨¡å‹

### åè®­ç»ƒæ•°æ®
é«˜è´¨é‡å¾®è°ƒæ•°æ®50wï¼Œè¯¥æ•°æ®ç»¼åˆè€ƒè™‘å¤§æ¨¡å‹é€šç”¨æŠ€èƒ½åŠ360å‚ç›´ä¸šåŠ¡æ•°æ®ï¼Œç”Ÿæˆæ–¹æ³•å¦‚ä¸‹ï¼š
   1. æ•°æ®å¤šæ ·æ€§ï¼šæ ¹æ®360è‡ªæœ‰æ ‡ç­¾ä½“ç³»è¿›è¡Œé¢†åŸŸï¼Œæ„å›¾ï¼Œéš¾åº¦ï¼Œé•¿åº¦çš„åˆ†å±‚é‡‡æ ·ï¼Œç¡®ä¿æŒ‡ä»¤å¤šæ ·æ€§
   2. æ•°æ®è´¨é‡ï¼šä½¿ç”¨ååºæ•°æ®è®­ç»ƒ360gpt-pro-rmï¼ˆreward benchå¾—åˆ†92.59ï¼‰ï¼Œç”¨è¯¥æ¨¡å‹è¿›è¡Œæ ·æœ¬ç­›é€‰ï¼Œè¿‡æ»¤æ‰ä½è´¨æ•°æ®
   3. å¤æ‚æŒ‡ä»¤è¿›åŒ–ï¼šä½¿ç”¨è¿›åŒ–æ–¹å¼åšå¤æ‚æŒ‡ä»¤ä¼˜åŒ–ï¼Œä¼˜åŒ–æŒ‡ä»¤è·Ÿéšèƒ½åŠ›

### è®­ç»ƒæ–¹æ³•
1. å…¨å‚æ•°å¾®è°ƒ

    åŸºäºé€šç”¨åè®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œå…¨å‚æ•°å¾®è°ƒ,é€‰æ‹©æœ€ä¼˜checkpointä½œä¸ºsft-baseã€‚

2. Lora offline DPOå¼ºåŒ–

    ä½¿ç”¨äººç±»æ ‡æ³¨å¥½çš„åå¥½pairå¯¹ï¼Œé‡‡ç”¨Loraæ–¹æ³•å¯¹sft-baseè¿›è¡Œloraå¾®è°ƒï¼Œç„¶åè¿›è¡Œlora DPOè®­ç»ƒã€‚

3. Iterative on-policy DPO å…¨å‚æ•°å¼ºåŒ–

    ä½¿ç”¨sft-baseæ¨¡å‹åœ¨è®­ç»ƒpromptä¸Šé‡‡æ ·å¤šä¸ªç­”æ¡ˆï¼Œç”¨360gpt-pro-rmæ‰“åˆ†ï¼Œå–æœ€é«˜æœ€ä½åˆ†ç»„pairè¿›è¡ŒDPOè®­ç»ƒã€‚æˆ‘ä»¬è¿­ä»£åœ°ä½¿ç”¨è¿™ç§on-policy DPOæå‡æ¨¡å‹æ•ˆæœã€‚

4. æ¨¡å‹åˆå¹¶
    
    åœ¨360å…¬å¸ç™½ç›’è¯„æµ‹é›†åˆ4ä¸Šï¼Œé’ˆå¯¹ä¸Šè¿°3ä¸ªæ¨¡å‹åšè‡ªåŠ¨è¯„æµ‹ï¼Œå‘ç°ä¸åŒæ¨¡å‹å„æœ‰å…¶ä¼˜åŠ¿æŠ€èƒ½ï¼Œè€ƒè™‘æ¨¡å‹åˆå¹¶æ–¹æ¡ˆï¼Œå¾—åˆ°æœ€ç»ˆçš„Chatæ¨¡å‹.

### æ¨¡å‹æ•ˆæœ
   æˆ‘ä»¬åœ¨IFEvalã€MT-benchã€CF-Benchä¸‰ä¸ªç»å…¸ä»»åŠ¡ä¸Šå¯¹ 360Zhinao2-7B-Chat-4k æ¨¡å‹è¿›è¡Œäº†è¯„æµ‹ï¼Œæ¨¡å‹æ•ˆæœå…·å¤‡è¾ƒå¼ºç«äº‰åŠ›ã€‚IFEval (prompt strict) ä»…æ¬¡äºGLM4-9B,åœ¨7Bå¼€æºæ¨¡å‹ä¸­å¾—åˆ†æœ€é«˜ï¼Œè¯¦ç»†ç»“æœå¦‚ä¸‹è¡¨:

| Model                | MT-bench | IFEval(strict prompt) | CFBench(CSR,ISR,PSR) |      |      |
|----------------------|----------|-----------------------|----------------------|------|------|
| Qwen2.5-7B-Instruct  | **8.07** | 0.556                 | **0.81**             | 0.46 | 0.57 |
| Yi-9B-16k-Chat       | 7.44     | 0.455                 | 0.75                 | 0.4  | 0.52 |
| GLM4-9B-Chat         | **8.08** | **0.634**             | **0.82**             | 0.48 | 0.61 |
| InternLM2.5-7B-Chat  | 7.39     | 0.540                 | 0.78                 | 0.4  | 0.54 |
| 360Zhinao2-7B-Chat-4k| 7.86     | **0.577**             | 0.8                  | 0.44 | 0.57 |



### é•¿æ–‡æœ¬å¾®è°ƒ
ä¸360Zhinao1å¼€æºæ—¶çš„åšæ³•åŸºæœ¬ä¸€è‡´ï¼Œæˆ‘ä»¬å°†RoPE baseä¾æ¬¡æ‰©å¤§ä¸º1000,000å’Œ50,000,000ï¼Œæ··åˆé•¿çŸ­æ–‡æœ¬çš„SFTæ•°æ®ä¾æ¬¡æ‹¼æ¥è‡³32kå’Œ360kï¼Œå°†gradient checkpointingã€ZeRO3 offloadå’Œring attentionç­‰æŠ€æœ¯ç»“åˆï¼Œä¾æ¬¡å¾®è°ƒå¾—åˆ°32kå’Œ360ké•¿æ–‡æœ¬æ¨¡å‹ã€‚åœ¨å„ä¸ª32k benchmarkä¸Šä½åˆ—ç¬¬ä¸€æ¢¯é˜Ÿã€‚

| Model                        | LooGLE-é•¿ä¾èµ–QA | Loong-Set 1 (32k) | LongBench-Chat (32kæˆªæ–­) | LEval-96é¢˜å­é›†èƒœç‡ | LEval-å®¢è§‚é¢˜å‡åˆ† |
|------------------------------|-----------------|-------------------|--------------------------|--------------------|------------------|
| GLM4-9B-Chat                 | 0.36            | 55.24             | 6.60                     | 0.49               | 63.96            |
| InternLM2.5-7B-Chat          | 0.39            | 42.76             | 5.70                     | 0.44               | 61.64            |
| 360Zhinao2-7B-Chat-32k       | 0.33            | 39.37             | 5.44                     | 0.44               | 60.48            |
| 360Zhinao2-7B-Chat-360k      | 0.34            | 32.16             | 5.08                     | 0.38               | 53.00            |
| Yi-1.5-9B-Chat               | 0.25            | 32.77             | 4.70                     | 0.37               | 56.22            |

<br>



# å¿«é€Ÿå¼€å§‹
ç®€å•çš„ç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•åˆ©ç”¨ğŸ¤– ModelScopeå’ŒğŸ¤— Transformerså¿«é€Ÿä½¿ç”¨360Zhinao2-7B-Baseå’Œ360Zhinao2-7B-Chat

## ä¾èµ–å®‰è£…
- python 3.8 and above
- pytorch 2.0 and above
- transformers 4.37.2 and above
- CUDA 11.4 and above are recommended.

```shell
pip install -r requirements.txt 
```
æˆ‘ä»¬æ¨èå®‰è£…flash-attentionï¼ˆå½“å‰å·²æ”¯æŒflash attention 2ï¼‰æ¥æé«˜ä½ çš„è¿è¡Œæ•ˆç‡ä»¥åŠé™ä½æ˜¾å­˜å ç”¨ã€‚(flash-attentionåªæ˜¯å¯é€‰é¡¹ï¼Œä¸å®‰è£…ä¹Ÿå¯æ­£å¸¸è¿è¡Œè¯¥é¡¹ç›®)

>flash-attn >= 2.3.6
```shell
FLASH_ATTENTION_FORCE_BUILD=TRUE pip install flash-attn==2.3.6
```


## ğŸ¤— Transformers
### Baseæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨transformerså¿«é€Ÿä½¿ç”¨360Zhinao2-7B-Baseæ¨¡å‹è¿›è¡Œæ¨ç†
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers.generation import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao2-7B-Base"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

inputs = tokenizer('ä¸­å›½äºŒåå››èŠ‚æ°”\n1. ç«‹æ˜¥\n2. é›¨æ°´\n3. æƒŠè›°\n4. æ˜¥åˆ†\n5. æ¸…æ˜\n', return_tensors='pt')
inputs = inputs.to(model.device)

pred = model.generate(input_ids=inputs["input_ids"], generation_config=generation_config)
print("outputs:\n", tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))
```

### Chatæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨transformerså¿«é€Ÿä½¿ç”¨360Zhinao2-7B-Chat-4Kæ¨¡å‹è¿›è¡Œæ¨ç†
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers.generation import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao2-7B-Chat-4K"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

messages = []
#round-1
messages.append({"role": "user", "content": "ä»‹ç»ä¸€ä¸‹åˆ˜å¾·å"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)

#round-2
messages.append({"role": "user", "content": "ä»–æœ‰ä»€ä¹ˆä»£è¡¨ä½œï¼Ÿ"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)
```

## ğŸ¤– ModelScope
### Baseæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨ModelScopeå¿«é€Ÿä½¿ç”¨360Zhinao2-7B-Baseæ¨¡å‹è¿›è¡Œæ¨ç†


```python
from modelscope import AutoModelForCausalLM, AutoTokenizer
from modelscope import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao2-7B-Base"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

inputs = tokenizer('ä¸­å›½äºŒåå››èŠ‚æ°”\n1. ç«‹æ˜¥\n2. é›¨æ°´\n3. æƒŠè›°\n4. æ˜¥åˆ†\n5. æ¸…æ˜\n', return_tensors='pt')
inputs = inputs.to(model.device)

pred = model.generate(input_ids=inputs["input_ids"], generation_config=generation_config)
print("outputs:\n", tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))
```

### Chatæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨ModelScopeå¿«é€Ÿä½¿ç”¨360Zhinao2-7B-Chat-4Kæ¨¡å‹è¿›è¡Œæ¨ç†
```python
from modelscope import AutoModelForCausalLM, AutoTokenizer
from modelscope import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao2-7B-Chat-4K"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

messages = []
#round-1
messages.append({"role": "user", "content": "ä»‹ç»ä¸€ä¸‹åˆ˜å¾·å"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)

#round-2
messages.append({"role": "user", "content": "ä»–æœ‰ä»€ä¹ˆä»£è¡¨ä½œï¼Ÿ"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)
```

## ç»ˆç«¯ Demo
å¯ä½¿ç”¨ç»ˆç«¯äº¤äº’å®ç°å¿«é€Ÿä½“éªŒ
```shell
python cli_demo.py
```
<p align="center">
    <img src="assets/cli_demo.gif" width="600" />
<p>

æ³¨ï¼šæˆ‘ä»¬å°šæœªæ”¯æŒMacä¸Š`device = 'mps'`ã€‚

## ç½‘é¡µ Demo
ä¹Ÿå¯ä½¿ç”¨ç½‘é¡µäº¤äº’å®ç°å¿«é€Ÿä½“éªŒ
```shell
streamlit run web_demo.py
```
<p align="center">
    <img src="assets/web_demo.gif" width="600" />
<p>

## API Demo
å¯åŠ¨å‘½ä»¤
```shell
python openai_api.py
```

è¯·æ±‚å‚æ•°
```shell
curl 'http://localhost:8360/v1/chat/completions' \
-H 'Content-Type: application/json' \
-d '{
    "max_new_tokens": 200,
    "do_sample": true,
    "top_k": 0,
    "top_p": 0.8,
    "temperature": 1.0,
    "repetition_penalty": 1.0,
    "messages": [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"}
    ]
}'
```

<br>

# æ¨¡å‹æ¨ç†
## æ¨¡å‹é‡åŒ–
æˆ‘ä»¬æä¾›äº†åŸºäºAutoGPTQçš„é‡åŒ–æ–¹æ¡ˆï¼Œå¹¶å¼€æºäº†Int4é‡åŒ–æ¨¡å‹ã€‚

## æ¨¡å‹éƒ¨ç½²
### vLLMå®‰è£…ç¯å¢ƒ
å¦‚å¸Œæœ›éƒ¨ç½²åŠåŠ é€Ÿæ¨ç†ï¼Œæˆ‘ä»¬å»ºè®®ä½ ä½¿ç”¨ `vLLM==0.3.3`ã€‚

å¦‚æœä½ ä½¿ç”¨**CUDA 12.1å’ŒPyTorch 2.1**ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…vLLMã€‚
```shell
pip install vllm==0.3.3
```

å¦åˆ™è¯·å‚è€ƒvLLMå®˜æ–¹çš„[å®‰è£…è¯´æ˜](https://docs.vllm.ai/en/latest/getting_started/installation.html)ã€‚

>å®‰è£…å®Œæˆåï¼Œè¿˜éœ€è¦ä»¥ä¸‹æ“ä½œ~
1. æŠŠvllm/zhinao.pyæ–‡ä»¶å¤åˆ¶åˆ°envç¯å¢ƒå¯¹åº”çš„vllm/model_executor/modelsç›®å½•ä¸‹ã€‚
2. æŠŠvllm/serving_chat.pyæ–‡ä»¶å¤åˆ¶åˆ°envç¯å¢ƒå¯¹åº”çš„vllm/entrypoints/openaiç›®å½•ä¸‹ã€‚
3. ç„¶ååœ¨vllm/model_executor/models/\_\_init\_\_.pyæ–‡ä»¶å¢åŠ ä¸€è¡Œä»£ç 

    ```shell
    "ZhinaoForCausalLM": ("zhinao", "ZhinaoForCausalLM"),
    ```

### vLLMæœåŠ¡å¯åŠ¨

å¯åŠ¨æœåŠ¡
```shell
python -m vllm.entrypoints.openai.api_server \
    --served-model-name 360Zhinao2-7B-Chat-4K \
    --model qihoo360/360Zhinao2-7B-Chat-4K \
    --trust-remote-code \
    --tensor-parallel-size 1 \
    --max-model-len 4096 \
    --host 0.0.0.0 \
    --port 8360
```

ä½¿ç”¨curlè¯·æ±‚æœåŠ¡
```shell
curl http://localhost:8360/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
    "model": "360Zhinao2-7B-Chat-4K",
    "max_tokens": 200,
    "top_k": -1,
    "top_p": 0.8,
    "temperature": 1.0,
    "presence_penalty": 0.0,
    "frequency_penalty": 0.0,
    "messages": [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"}
    ],
    "stop": [
        "<eod>",
        "<|im_end|>",
        "<|im_start|>"
    ]
}'
```
ä½¿ç”¨pythonè¯·æ±‚æœåŠ¡
```python
from openai import OpenAI
# Set OpenAI's API key and API base to use vLLM's API server.
openai_api_key = "EMPTY"
openai_api_base = "http://localhost:8360/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

chat_response = client.chat.completions.create(
    model="360Zhinao2-7B-Chat-4K",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stop=[
        "<eod>",
        "<|im_end|>",
        "<|im_start|>"
    ],
    presence_penalty=0.0,
    frequency_penalty=0.0
)
print("Chat response:", chat_response)
```

> æ³¨æ„ï¼šå¦‚éœ€è¦å¼€å¯é‡å¤æƒ©ç½šï¼Œå»ºè®®ä½¿ç”¨ *presence_penalty* å’Œ *frequency_penalty* å‚æ•°ã€‚

<br>

# æ¨¡å‹å¾®è°ƒ
## è®­ç»ƒæ•°æ®

æˆ‘ä»¬æä¾›äº†å¾®è°ƒè®­ç»ƒæ ·ä¾‹æ•°æ® data/test.jsonï¼Œè¯¥æ ·ä¾‹æ•°æ®æ˜¯ä» [multiturn_chat_0.8M](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M) é‡‡æ ·å‡º 1 ä¸‡æ¡ï¼Œå¹¶ä¸”åšäº†æ ¼å¼è½¬æ¢ã€‚

æ•°æ®æ ¼å¼:
```json
[
  {
    "id": 1,
    "conversations": [
        {
            "from": "system",
            "value": "You are a helpful assistant."
        },
        {
            "from": "user",
            "value": "æ‚¨å¥½å•Š"
        },
        {
            "from": "assistant",
            "value": "ä½ å¥½ï¼æˆ‘ä»Šå¤©èƒ½ä¸ºæ‚¨åšäº›ä»€ä¹ˆï¼Ÿæœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€è¦å¸®åŠ©å—? æˆ‘åœ¨è¿™é‡Œä¸ºæ‚¨æä¾›æœåŠ¡ã€‚"
        }
    ]
  }
]
```

## å¾®è°ƒè®­ç»ƒ
è®­ç»ƒè„šæœ¬å¦‚ä¸‹ï¼š
```shell
set -x

HOSTFILE=hostfile
DS_CONFIG=./finetune/ds_config_zero2.json

# PARAMS
LR=5e-6
EPOCHS=3
MAX_LEN=4096
BATCH_SIZE=4
NUM_NODES=1
NUM_GPUS=8
MASTER_PORT=29500

IS_CONCAT=False # æ˜¯å¦æ•°æ®æ‹¼æ¥åˆ°æœ€å¤§é•¿åº¦ï¼ˆMAX_LENï¼‰

DATA_PATH="./data/training_data_sample.json"
MODEL_PATH="qihoo360/360Zhinao2-7B-Base"
OUTPUT_DIR="./outputs/"

deepspeed --hostfile ${HOSTFILE} \
        --master_port ${MASTER_PORT} \
        --num_nodes ${NUM_NODES} \
        --num_gpus ${NUM_GPUS} \
        finetune.py \
        --report_to "tensorboard" \
        --data_path ${DATA_PATH} \
        --model_name_or_path ${MODEL_PATH} \
        --output_dir ${OUTPUT_DIR} \
        --model_max_length ${MAX_LEN} \
        --num_train_epochs ${EPOCHS} \
        --per_device_train_batch_size ${BATCH_SIZE} \
        --gradient_accumulation_steps 1 \
        --save_strategy steps \
        --save_steps 200 \
        --learning_rate ${LR} \
        --lr_scheduler_type cosine \
        --adam_beta1 0.9 \
        --adam_beta2 0.95 \
        --adam_epsilon 1e-8 \
        --max_grad_norm 1.0 \
        --weight_decay 0.1 \
        --warmup_ratio 0.01 \
        --gradient_checkpointing True \
        --bf16 True \
        --tf32 True \
        --deepspeed ${DS_CONFIG} \
        --is_concat ${IS_CONCAT} \
        --logging_steps 1 \
        --log_on_each_node False
```
```shell
bash finetune/ds_finetune.sh
```
- å¯é€šè¿‡é…ç½®hostfileï¼Œå®ç°å•æœºã€å¤šæœºè®­ç»ƒã€‚
- å¯é€šè¿‡é…ç½®ds_configï¼Œå®ç°zero2ã€zero3ã€‚
- å¯é€šè¿‡é…ç½®fp16ã€bf16å®ç°æ··åˆç²¾åº¦è®­ç»ƒï¼Œå»ºè®®ä½¿ç”¨bf16ï¼Œä¸é¢„è®­ç»ƒæ¨¡å‹ä¿æŒä¸€è‡´ã€‚
- å¯é€šè¿‡é…ç½®is_concatå‚æ•°ï¼Œæ§åˆ¶è®­ç»ƒæ•°æ®æ˜¯å¦æ‹¼æ¥ï¼Œå½“è®­ç»ƒæ•°æ®é‡çº§è¾ƒå¤§æ—¶ï¼Œå¯é€šè¿‡æ‹¼æ¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

<br>

# è®¸å¯è¯

æœ¬ä»“åº“æºç éµå¾ªå¼€æºè®¸å¯è¯Apache 2.0ã€‚

360æ™ºè„‘å¼€æºæ¨¡å‹æ”¯æŒå…è´¹å•†ç”¨ï¼Œæ— éœ€å‘æˆ‘ä»¬è¿›è¡Œç‰¹æ®Šç”³è¯·ã€‚
